{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1><span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#2.-선형회귀(Linear-Regression)\" data-toc-modified-id=\"2.-선형회귀(Linear-Regression)-1\">2. 선형회귀(Linear Regression)</a></span></li><li><span><a href=\"#2.1-선형회귀(Linear-Regression)\" data-toc-modified-id=\"2.1-선형회귀(Linear-Regression)-2\">2.1 선형회귀(Linear Regression)</a></span></li><li><span><a href=\"#2.1.5-파이토치로-선형-회귀-구현하기\" data-toc-modified-id=\"2.1.5-파이토치로-선형-회귀-구현하기-3\">2.1.5 파이토치로 선형 회귀 구현하기</a></span></li><li><span><a href=\"#2.1.6-optimizer.zero_grad()가-필요한-이유\" data-toc-modified-id=\"2.1.6-optimizer.zero_grad()가-필요한-이유-4\">2.1.6 optimizer.zero_grad()가 필요한 이유</a></span></li><li><span><a href=\"#2.2-자동미분\" data-toc-modified-id=\"2.2-자동미분-5\">2.2 자동미분</a></span></li><li><span><a href=\"#2.3-다중-선형-회귀\" data-toc-modified-id=\"2.3-다중-선형-회귀-6\">2.3 다중 선형 회귀</a></span></li><li><span><a href=\"#2.4-nn.Module로-구현하는-선형-회귀\" data-toc-modified-id=\"2.4-nn.Module로-구현하는-선형-회귀-7\">2.4 nn.Module로 구현하는 선형 회귀</a></span></li><li><span><a href=\"#2.5-클래스로-파이토치-모델-구현하기\" data-toc-modified-id=\"2.5-클래스로-파이토치-모델-구현하기-8\">2.5 클래스로 파이토치 모델 구현하기</a></span></li><li><span><a href=\"#2.6-미니-배치와-데이터-로드(Mini-Batch-and-Data-Load)\" data-toc-modified-id=\"2.6-미니-배치와-데이터-로드(Mini-Batch-and-Data-Load)-9\">2.6 미니 배치와 데이터 로드(Mini Batch and Data Load)</a></span></li><li><span><a href=\"#2.6.1-미니-배치와-배치-크기(Mini-Batch-and-Batch-Size)\" data-toc-modified-id=\"2.6.1-미니-배치와-배치-크기(Mini-Batch-and-Batch-Size)-10\">2.6.1 미니 배치와 배치 크기(Mini Batch and Batch Size)</a></span></li><li><span><a href=\"#2.6.2-이터레이션(Iteration)\" data-toc-modified-id=\"2.6.2-이터레이션(Iteration)-11\">2.6.2 이터레이션(Iteration)</a></span></li><li><span><a href=\"#2.6.3-데이터-로드하기(Data-Load)\" data-toc-modified-id=\"2.6.3-데이터-로드하기(Data-Load)-12\">2.6.3 데이터 로드하기(Data Load)</a></span></li><li><span><a href=\"#2.7-커스텀-데이터셋(Custom-Dataset)\" data-toc-modified-id=\"2.7-커스텀-데이터셋(Custom-Dataset)-13\">2.7 커스텀 데이터셋(Custom Dataset)</a></span></li><li><span><a href=\"#2.8-활용\" data-toc-modified-id=\"2.8-활용-14\">2.8 활용</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출처 : https://github.com/Namsik-Yoon/pytorch_basic/blob/master/2.%20%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80(Linear_Regression).ipynb \n",
    "\n",
    "이번에도 몰래 가져왔다. 이번에도 필사를 필사적으로 해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 선형회귀(Linear Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 선형회귀(Linear Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습목표 : 아래 개념들을 잘 이해하자\n",
    "\n",
    "데이터에 대한 이해(Data Definition)\n",
    "\n",
    "가설(Hypothesis) 수립\n",
    "\n",
    "손실 계산하기(Compute loss)\n",
    "\n",
    "경사 하강법(Gradient Descent)\n",
    "\n",
    "이번 장에 아주 좋은 말이 많은데, 나는 이미 이해해서 또 쓰기 귀찮다.\n",
    "\n",
    "https://wikidocs.net/53560\n",
    "\n",
    "링크를 참고하면 정말 좋은 이야기가 많다.\n",
    "\n",
    "2.1.1 데이터에 대한 이해(Data Definition)\n",
    "\n",
    "2.1.2 가설(Hypothesis) 수립\n",
    "\n",
    "2.1.3 비용 함수(Cost function)에 대한 이해\n",
    "\n",
    "2.1.4 옵티마이저 - 경사 하강법(Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.5 파이토치로 선형 회귀 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:20:23.208265Z",
     "start_time": "2020-04-06T10:20:22.556977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x28c7a3736b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1) # 파이썬 코드를 재실행해도 같은 결과가 나오도록 랜덤 시드(random seed)를 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:20:23.784695Z",
     "start_time": "2020-04-06T10:20:23.779709Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1],\n",
    "                            [2],\n",
    "                            [3]])\n",
    "y_train = torch.FloatTensor([[2],\n",
    "                            [4],\n",
    "                            [6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선형 회귀란 학습 데이터와 가장 잘 맞는 하나의 직선을 찾는 일이다.\n",
    "\n",
    "y = W*x + b\n",
    "\n",
    "가장 잘 맞는 직선은 W와 b로 정의한다. W는 가중치, b는 편향이다.\n",
    "\n",
    "즉, 선형 회귀의 목표는 W와 b를 찾는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:20:25.008452Z",
     "start_time": "2020-04-06T10:20:24.995473Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], requires_grad=True)\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "W = torch.zeros(1, requires_grad=True) \n",
    "# requres_grad=True는 텐서에 행해지는 모든 연산에 대해 미분값을 계산한다.\n",
    "# 학습을 통해 계속 값이 변경되는 변수임을 의미한다.\n",
    "print(W)\n",
    "\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 상태는 \n",
    "\n",
    "y = 0*x + 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:20:26.288999Z",
     "start_time": "2020-04-06T10:20:26.284013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "hypothesis = W * x_train + b\n",
    "print(hypothesis)\n",
    "print(hypothesis.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비용 함수를 선언하자. 난 아직까지 식을 눈으로 봐야 편하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://render.githubusercontent.com/render/math?math=cost%28W%2Cb%29%20%3D%20%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5By%5E%7B%28i%29%7D%20-%20H%28x%5E%7B%28i%29%7D%29%5D%5E%7B2%7D&mode=inline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:20:27.991477Z",
     "start_time": "2020-04-06T10:20:27.987460Z"
    }
   },
   "outputs": [],
   "source": [
    "cost = torch.mean((hypothesis-y_train)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:20:28.518041Z",
     "start_time": "2020-04-06T10:20:28.514076Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([W, b], lr=0.01) \n",
    "#학습 대상인 W와 b가 SGD에 입력된다. lr은 학습률(learnign rate)을 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:20:29.123440Z",
     "start_time": "2020-04-06T10:20:29.114457Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer.zero_grad() # 미분을 통해 얻은 기울기를 0으로 초기화한다. \n",
    "cost.backward() # 가중치 W와 편향 b에 대한 기울기가 계산된다.\n",
    "optimizer.step() # 인수로 들어갔던 W와 b에 리턴되는 변수들의 기울기에 학습률을 곱하여 빼줌으로써 업데이트한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기까지를 다시 한번에 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:20:30.721158Z",
     "start_time": "2020-04-06T10:20:30.170649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2000 W: 0.187 b: 0.08 Cost: 18.667\n",
      "Epoch 100/2000 W: 1.746 b: 0.578 Cost: 0.048\n",
      "Epoch 200/2000 W: 1.8 b: 0.454 Cost: 0.03\n",
      "Epoch 300/2000 W: 1.843 b: 0.357 Cost: 0.018\n",
      "Epoch 400/2000 W: 1.876 b: 0.281 Cost: 0.011\n",
      "Epoch 500/2000 W: 1.903 b: 0.221 Cost: 0.007\n",
      "Epoch 600/2000 W: 1.924 b: 0.174 Cost: 0.004\n",
      "Epoch 700/2000 W: 1.94 b: 0.136 Cost: 0.003\n",
      "Epoch 800/2000 W: 1.953 b: 0.107 Cost: 0.002\n",
      "Epoch 900/2000 W: 1.963 b: 0.084 Cost: 0.001\n",
      "Epoch 1000/2000 W: 1.971 b: 0.066 Cost: 0.001\n",
      "Epoch 1100/2000 W: 1.977 b: 0.052 Cost: 0.0\n",
      "Epoch 1200/2000 W: 1.982 b: 0.041 Cost: 0.0\n",
      "Epoch 1300/2000 W: 1.986 b: 0.032 Cost: 0.0\n",
      "Epoch 1400/2000 W: 1.989 b: 0.025 Cost: 0.0\n",
      "Epoch 1500/2000 W: 1.991 b: 0.02 Cost: 0.0\n",
      "Epoch 1600/2000 W: 1.993 b: 0.016 Cost: 0.0\n",
      "Epoch 1700/2000 W: 1.995 b: 0.012 Cost: 0.0\n",
      "Epoch 1800/2000 W: 1.996 b: 0.01 Cost: 0.0\n",
      "Epoch 1900/2000 W: 1.997 b: 0.008 Cost: 0.0\n",
      "Epoch 2000/2000 W: 1.997 b: 0.006 Cost: 0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1) # 파이썬 코드를 재실행해도 같은 결과가 나오도록 랜덤 시드(random seed)를 준다.\n",
    "\n",
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1],\n",
    "                             [2],\n",
    "                             [3]])\n",
    "y_train = torch.FloatTensor([[2],\n",
    "                             [4],\n",
    "                             [6]])\n",
    "\n",
    "# 모델 초기화\n",
    "W = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=0.01)\n",
    "\n",
    "nb_epochs = 2000 # 원하는만큼 경사 하강법을 반복\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    hypothesis = x_train * W + b\n",
    "\n",
    "    # cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}/{nb_epochs} W: {round(W.item(),3)} b: {round(b.item(),3)} Cost: {round(cost.item(),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.6 optimizer.zero_grad()가 필요한 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이토치는 미분을 통해 얻은 기울기를 누적시키는 특징이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:20:35.297916Z",
     "start_time": "2020-04-06T10:20:35.280986Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수식을 w로 미분한 값:2.0\n",
      "수식을 w로 미분한 값:4.0\n",
      "수식을 w로 미분한 값:6.0\n",
      "수식을 w로 미분한 값:8.0\n",
      "수식을 w로 미분한 값:10.0\n",
      "수식을 w로 미분한 값:12.0\n",
      "수식을 w로 미분한 값:14.0\n",
      "수식을 w로 미분한 값:16.0\n",
      "수식을 w로 미분한 값:18.0\n",
      "수식을 w로 미분한 값:20.0\n",
      "수식을 w로 미분한 값:22.0\n",
      "수식을 w로 미분한 값:24.0\n",
      "수식을 w로 미분한 값:26.0\n",
      "수식을 w로 미분한 값:28.0\n",
      "수식을 w로 미분한 값:30.0\n",
      "수식을 w로 미분한 값:32.0\n",
      "수식을 w로 미분한 값:34.0\n",
      "수식을 w로 미분한 값:36.0\n",
      "수식을 w로 미분한 값:38.0\n",
      "수식을 w로 미분한 값:40.0\n",
      "수식을 w로 미분한 값:42.0\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs+1):\n",
    "    z=2*w\n",
    "    z.backward()\n",
    "    print(f'수식을 w로 미분한 값:{w.grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "계속해서 미분한 값이 2씩 누적된다. 그래서 optimizer.zero_grad()로 초기화 시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 자동미분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좋은 내용인데 건너 뛴다.\n",
    "\n",
    "https://wikidocs.net/60754"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 다중 선형 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "난 전체 코드만 쓰겠다.\n",
    "\n",
    "설명은 아래 참고\n",
    "\n",
    "https://wikidocs.net/54841"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:20:39.515642Z",
     "start_time": "2020-04-06T10:20:38.995034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/2000  Cost: 29661.80078125\n",
      "Epoch: 100/2000  Cost: 1.5636341571807861\n",
      "Epoch: 200/2000  Cost: 1.4976075887680054\n",
      "Epoch: 300/2000  Cost: 1.4350258111953735\n",
      "Epoch: 400/2000  Cost: 1.3757301568984985\n",
      "Epoch: 500/2000  Cost: 1.3195109367370605\n",
      "Epoch: 600/2000  Cost: 1.2662220001220703\n",
      "Epoch: 700/2000  Cost: 1.2156963348388672\n",
      "Epoch: 800/2000  Cost: 1.1678180694580078\n",
      "Epoch: 900/2000  Cost: 1.1224288940429688\n",
      "Epoch: 1000/2000  Cost: 1.0793777704238892\n",
      "Epoch: 1100/2000  Cost: 1.0385843515396118\n",
      "Epoch: 1200/2000  Cost: 0.999893844127655\n",
      "Epoch: 1300/2000  Cost: 0.9632169604301453\n",
      "Epoch: 1400/2000  Cost: 0.9284208416938782\n",
      "Epoch: 1500/2000  Cost: 0.8954533338546753\n",
      "Epoch: 1600/2000  Cost: 0.8641611337661743\n",
      "Epoch: 1700/2000  Cost: 0.8345034718513489\n",
      "Epoch: 1800/2000  Cost: 0.8063748478889465\n",
      "Epoch: 1900/2000  Cost: 0.7796962857246399\n",
      "Epoch: 2000/2000  Cost: 0.7543892860412598\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                            [93, 88, 93],\n",
    "                            [89, 91, 90],\n",
    "                            [96, 98, 100],\n",
    "                            [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152],\n",
    "                            [185],\n",
    "                            [180],\n",
    "                            [196],\n",
    "                            [142]])\n",
    "\n",
    "#모델 초기화\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=1e-5)\n",
    "\n",
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs+1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    # 편향 b는 브로드캐스팅되어 각 샘플에 더해진다.\n",
    "    hypothesis = x_train.matmul(W) + b\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 100번마다 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch: {epoch}/{nb_epochs}  Cost: {cost.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 nn.Module로 구현하는 선형 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사실 직접 정의할 필요없이 다 구현되어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:20:42.368018Z",
     "start_time": "2020-04-06T10:20:41.859377Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/2000  Cost: 31667.59765625\n",
      "Epoch: 100/2000  Cost: 0.22599251568317413\n",
      "Epoch: 200/2000  Cost: 0.22391095757484436\n",
      "Epoch: 300/2000  Cost: 0.22194059193134308\n",
      "Epoch: 400/2000  Cost: 0.2200593650341034\n",
      "Epoch: 500/2000  Cost: 0.21827054023742676\n",
      "Epoch: 600/2000  Cost: 0.21657471358776093\n",
      "Epoch: 700/2000  Cost: 0.21495017409324646\n",
      "Epoch: 800/2000  Cost: 0.21341314911842346\n",
      "Epoch: 900/2000  Cost: 0.21195237338542938\n",
      "Epoch: 1000/2000  Cost: 0.21055936813354492\n",
      "Epoch: 1100/2000  Cost: 0.20923027396202087\n",
      "Epoch: 1200/2000  Cost: 0.20796680450439453\n",
      "Epoch: 1300/2000  Cost: 0.2067623883485794\n",
      "Epoch: 1400/2000  Cost: 0.20561793446540833\n",
      "Epoch: 1500/2000  Cost: 0.2045292854309082\n",
      "Epoch: 1600/2000  Cost: 0.2034807652235031\n",
      "Epoch: 1700/2000  Cost: 0.2024863213300705\n",
      "Epoch: 1800/2000  Cost: 0.20153871178627014\n",
      "Epoch: 1900/2000  Cost: 0.20063427090644836\n",
      "Epoch: 2000/2000  Cost: 0.1997702270746231\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                            [93, 88, 93],\n",
    "                            [89, 91, 90],\n",
    "                            [96, 98, 100],\n",
    "                            [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152],\n",
    "                            [185],\n",
    "                            [180],\n",
    "                            [196],\n",
    "                            [142]])\n",
    "\n",
    "model = nn.Linear(3,1) # 단순 선형 회귀는 (1,1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs+1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 100번마다 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch: {epoch}/{nb_epochs}  Cost: {cost.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:20:45.008956Z",
     "start_time": "2020-04-06T10:20:45.002005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 73, 80, 75일 때의 예측값: \n",
      "tensor([[151.2306]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "new_var = torch.FloatTensor([[73, 80, 75]])\n",
    "pred_y = model(new_var)\n",
    "print(f'훈련 후 입력이 73, 80, 75일 때의 예측값: \\n{pred_y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 클래스로 파이토치 모델 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "안한다.\n",
    "\n",
    "https://wikidocs.net/60036"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.6 미니 배치와 데이터 로드(Mini Batch and Data Load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.6.1 미니 배치와 배치 크기(Mini Batch and Batch Size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이거는 맨날 헷갈린다. 볼수록 좋은 내용인 것 같다.\n",
    "\n",
    "![](https://camo.githubusercontent.com/2d645ca96027a2b35f7e29bc00144044fc8301fd/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f35353538302f2545422541462542382545422538422538382545422542302542302545432542392539382e504e47)\n",
    "\n",
    "미니 배치 학습을 하게되면 미니 배치만큼만 가져가서 cost를 계산하고 경사 하강법을 수행한다.\n",
    "\n",
    "그리고 다음 미니 배치를 가져가서 cost를 계산하고 경사 하강법을 수행한다.\n",
    "\n",
    "그림 기준으로 5번까지 하면 1epoch가 끝나는 거다.\n",
    "\n",
    "정리 1: \n",
    "\n",
    "전체 데이터에 대해 경사 하강법 수행하면 '배치 경사 하강법' \n",
    "\n",
    "미니 배치 단위로 경사 하강법 수행하면 '미니 배치 경사 하강법'\n",
    "\n",
    "정리 2:\n",
    "\n",
    "배치 경사 하강법은 전체 데이터를 사용하므로 가중치 값이 최적값에 수렴하는 과정이 매우 안정적이지만, 계산량이 너무 많이 든다.\n",
    "\n",
    "미니 배치 경사 하강법은 일부 데이터를 사용하므로 최적값으로 수렴하는 과정에서 헤매기도 하지만 훈련 속도가 빠르다.\n",
    "\n",
    "정리 3:\n",
    "\n",
    "배치 크기는 2의 제곱수를 사용한다. CPU,GPU의 메모리가 2의 배수이기 때문에 데이터 송수신의 효율을 높일 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.6.2 이터레이션(Iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://camo.githubusercontent.com/8fc6da3c8d343d521e7ae31d352e1ebaf2e4ca0e/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f33363033332f6261746368616e6465706f6368697465726174696f6e2e504e47)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이터레이션 : 1 epoch 내에서 매개변수(W, b)의 업데이트 횟수\n",
    "\n",
    "전체 데이터가 2000이고 배치 크기가 200일 때 이터레이션의 수는 총 10개이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.6.3 데이터 로드하기(Data Load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋(Dataset)과 데이터로더(DataLoader)를 사용하면 미니 배치 학습, 데이터 셔플(shuffle), 병렬 처리까지 간단히 수행할 수 있다.\n",
    "\n",
    "Dataset를 정의하고 이를 DataLoader에 전달하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:20:49.519898Z",
     "start_time": "2020-04-06T10:20:49.515909Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:20:49.984656Z",
     "start_time": "2020-04-06T10:20:49.978672Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
    "                               [93,  88,  93], \n",
    "                               [89,  91,  90], \n",
    "                               [96,  98,  100],   \n",
    "                               [73,  66,  70]])  \n",
    "y_train  =  torch.FloatTensor([[152],\n",
    "                               [185],\n",
    "                               [180],\n",
    "                               [196],\n",
    "                               [142]])\n",
    "                              \n",
    "dataset = TensorDataset(x_train, y_train) # 데이터셋 만들기\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True) # 데이터로더 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataloader는 기본적으로 2개의 인자를 입력받는다. 하나는 데이터셋, 미니 배치의 크기이다.\n",
    "\n",
    "이때 미니 배치의 크기는 통상적으로 2의 배수를 사용한다.\n",
    "\n",
    "shuffle=True를 선택하면 Epoch마다 데이터셋을 섞어서 데이터가 학습되는 순서를 바꾼다.\n",
    "\n",
    "[사람도 같은 문제지를 계속 풀면 어느 순간 문제의 순서에 익숙해질 수 있습니다. 예를 들어 어떤 문제지의 12번 문제를 풀면서, '13번 문제가 뭔지는 기억은 안 나지만 어제 풀었던 기억으로 정답은 5번이었던 것 같은데' 하면서 문제 자체보단 순서에 익숙해질 수 있다는 것입니다. 그럴 때 문제지를 풀 때마다 문제 순서를 랜덤으로 바꾸면 도움이 될 겁니다. 마찬가지로 모델이 데이터셋의 순서에 익숙해지는 것을 방지하여 학습할 때는 이 옵션을 True를 주는 것을 권장합니다.]\n",
    "\n",
    "뭔가 이상하긴 한데 그런 느낌인가 보다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:20:53.581066Z",
     "start_time": "2020-04-06T10:20:53.546135Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2\n",
      "--------------------------------------------------\n",
      "batch_idx: 0\n",
      "samples: [tensor([[ 96.,  98., 100.],\n",
      "        [ 89.,  91.,  90.]]), tensor([[196.],\n",
      "        [180.]])]\n",
      "Batch 1/3\n",
      "batch_idx: 1\n",
      "samples: [tensor([[73., 80., 75.],\n",
      "        [73., 66., 70.]]), tensor([[152.],\n",
      "        [142.]])]\n",
      "Batch 2/3\n",
      "batch_idx: 2\n",
      "samples: [tensor([[93., 88., 93.]]), tensor([[185.]])]\n",
      "Batch 3/3\n",
      "--------------------------------------------------\n",
      "Cost: 5174.39599609375\n",
      "--------------------------------------------------\n",
      "Epoch 1/2\n",
      "--------------------------------------------------\n",
      "batch_idx: 0\n",
      "samples: [tensor([[89., 91., 90.],\n",
      "        [73., 80., 75.]]), tensor([[180.],\n",
      "        [152.]])]\n",
      "Batch 1/3\n",
      "batch_idx: 1\n",
      "samples: [tensor([[ 73.,  66.,  70.],\n",
      "        [ 96.,  98., 100.]]), tensor([[142.],\n",
      "        [196.]])]\n",
      "Batch 2/3\n",
      "batch_idx: 2\n",
      "samples: [tensor([[93., 88., 93.]]), tensor([[185.]])]\n",
      "Batch 3/3\n",
      "--------------------------------------------------\n",
      "Cost: 212.29489135742188\n",
      "--------------------------------------------------\n",
      "Epoch 2/2\n",
      "--------------------------------------------------\n",
      "batch_idx: 0\n",
      "samples: [tensor([[93., 88., 93.],\n",
      "        [73., 80., 75.]]), tensor([[185.],\n",
      "        [152.]])]\n",
      "Batch 1/3\n",
      "batch_idx: 1\n",
      "samples: [tensor([[ 89.,  91.,  90.],\n",
      "        [ 96.,  98., 100.]]), tensor([[180.],\n",
      "        [196.]])]\n",
      "Batch 2/3\n",
      "batch_idx: 2\n",
      "samples: [tensor([[73., 66., 70.]]), tensor([[142.]])]\n",
      "Batch 3/3\n",
      "--------------------------------------------------\n",
      "Cost: 41.47127151489258\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(3,1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "nb_epochs = 2\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    print(f'Epoch {epoch}/{nb_epochs}')\n",
    "    print('-'*50)\n",
    "\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        print('batch_idx:', batch_idx)\n",
    "        print('samples:', samples)\n",
    "        x_train, y_train = samples\n",
    "    \n",
    "        # H(x) 계산\n",
    "        prediction = model(x_train)\n",
    "\n",
    "        # cost 계산\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "        # cost로 H(x) 계산\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Batch {batch_idx+1}/{len(dataloader)}')\n",
    "\n",
    "    print('-'*50)\n",
    "    print(f'Cost: {cost.item()}')\n",
    "    print('-'*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.7 커스텀 데이터셋(Custom Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:20:57.639194Z",
     "start_time": "2020-04-06T10:20:57.634218Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    # 데이터셋의 전처리를 해주는 부분\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    # 데이터셋의 길이, 즉 총 샘플의 수를 적어주는 부분\n",
    "    def __len__(self):\n",
    "        return\n",
    "    \n",
    "    # 데이터셋에서 특정 1개의 샘플을 가져오는 함수\n",
    "    def __getitem__(self, idx):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:21:00.434745Z",
     "start_time": "2020-04-06T10:21:00.426742Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CustomDataset(Dataset): \n",
    "    # 데이터셋의 전처리를 해주는 부분\n",
    "    def __init__(self):\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                       [93, 88, 93],\n",
    "                       [89, 91, 90],\n",
    "                       [96, 98, 100],\n",
    "                       [73, 66, 70]]\n",
    "        self.y_data = [[152], \n",
    "                       [185],\n",
    "                       [180],\n",
    "                       [196],\n",
    "                       [142]]\n",
    "\n",
    "    # 데이터셋의 길이, 즉 총 샘플의 수를 적어주는 부분\n",
    "    def __len__(self): \n",
    "        return len(self.x_data)\n",
    "\n",
    "    # 데이터셋에서 특정 1개의 샘플을 가져오는 함수\n",
    "    def __getitem__(self, idx): \n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:21:03.296071Z",
     "start_time": "2020-04-06T10:21:03.291086Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = CustomDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "model = torch.nn.Linear(3,1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:21:04.714281Z",
     "start_time": "2020-04-06T10:21:04.658453Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/20 Batch 1/3 Cost: 23817.884765625\n",
      "Epoch 0/20 Batch 2/3 Cost: 12629.80859375\n",
      "Epoch 0/20 Batch 3/3 Cost: 1490.0264892578125\n",
      "Epoch 1/20 Batch 1/3 Cost: 1102.735595703125\n",
      "Epoch 1/20 Batch 2/3 Cost: 152.0546875\n",
      "Epoch 1/20 Batch 3/3 Cost: 169.6377410888672\n",
      "Epoch 2/20 Batch 1/3 Cost: 15.403888702392578\n",
      "Epoch 2/20 Batch 2/3 Cost: 15.917740821838379\n",
      "Epoch 2/20 Batch 3/3 Cost: 2.6757023334503174\n",
      "Epoch 3/20 Batch 1/3 Cost: 3.2349371910095215\n",
      "Epoch 3/20 Batch 2/3 Cost: 5.103827476501465\n",
      "Epoch 3/20 Batch 3/3 Cost: 5.206399440765381\n",
      "Epoch 4/20 Batch 1/3 Cost: 4.732839107513428\n",
      "Epoch 4/20 Batch 2/3 Cost: 4.18689489364624\n",
      "Epoch 4/20 Batch 3/3 Cost: 4.310299396514893\n",
      "Epoch 5/20 Batch 1/3 Cost: 1.0817984342575073\n",
      "Epoch 5/20 Batch 2/3 Cost: 4.83293342590332\n",
      "Epoch 5/20 Batch 3/3 Cost: 7.471467018127441\n",
      "Epoch 6/20 Batch 1/3 Cost: 3.5455799102783203\n",
      "Epoch 6/20 Batch 2/3 Cost: 0.7308382391929626\n",
      "Epoch 6/20 Batch 3/3 Cost: 7.113091468811035\n",
      "Epoch 7/20 Batch 1/3 Cost: 3.9544317722320557\n",
      "Epoch 7/20 Batch 2/3 Cost: 3.409435272216797\n",
      "Epoch 7/20 Batch 3/3 Cost: 0.12771767377853394\n",
      "Epoch 8/20 Batch 1/3 Cost: 4.548311233520508\n",
      "Epoch 8/20 Batch 2/3 Cost: 2.3762197494506836\n",
      "Epoch 8/20 Batch 3/3 Cost: 0.029777521267533302\n",
      "Epoch 9/20 Batch 1/3 Cost: 3.4834351539611816\n",
      "Epoch 9/20 Batch 2/3 Cost: 2.5416111946105957\n",
      "Epoch 9/20 Batch 3/3 Cost: 4.151369094848633\n",
      "Epoch 10/20 Batch 1/3 Cost: 2.3607373237609863\n",
      "Epoch 10/20 Batch 2/3 Cost: 1.7879865169525146\n",
      "Epoch 10/20 Batch 3/3 Cost: 7.507295608520508\n",
      "Epoch 11/20 Batch 1/3 Cost: 3.0393075942993164\n",
      "Epoch 11/20 Batch 2/3 Cost: 4.50801944732666\n",
      "Epoch 11/20 Batch 3/3 Cost: 0.0378732830286026\n",
      "Epoch 12/20 Batch 1/3 Cost: 4.480140686035156\n",
      "Epoch 12/20 Batch 2/3 Cost: 1.4995269775390625\n",
      "Epoch 12/20 Batch 3/3 Cost: 2.935249090194702\n",
      "Epoch 13/20 Batch 1/3 Cost: 0.7827144265174866\n",
      "Epoch 13/20 Batch 2/3 Cost: 3.3810760974884033\n",
      "Epoch 13/20 Batch 3/3 Cost: 6.1926069259643555\n",
      "Epoch 14/20 Batch 1/3 Cost: 1.6219040155410767\n",
      "Epoch 14/20 Batch 2/3 Cost: 6.218507766723633\n",
      "Epoch 14/20 Batch 3/3 Cost: 3.6191439628601074\n",
      "Epoch 15/20 Batch 1/3 Cost: 2.3731491565704346\n",
      "Epoch 15/20 Batch 2/3 Cost: 4.798120498657227\n",
      "Epoch 15/20 Batch 3/3 Cost: 0.0922774076461792\n",
      "Epoch 16/20 Batch 1/3 Cost: 3.4306957721710205\n",
      "Epoch 16/20 Batch 2/3 Cost: 4.806702613830566\n",
      "Epoch 16/20 Batch 3/3 Cost: 1.8887791633605957\n",
      "Epoch 17/20 Batch 1/3 Cost: 3.8795220851898193\n",
      "Epoch 17/20 Batch 2/3 Cost: 2.309389114379883\n",
      "Epoch 17/20 Batch 3/3 Cost: 4.901613235473633\n",
      "Epoch 18/20 Batch 1/3 Cost: 3.786149024963379\n",
      "Epoch 18/20 Batch 2/3 Cost: 4.070049285888672\n",
      "Epoch 18/20 Batch 3/3 Cost: 0.035356808453798294\n",
      "Epoch 19/20 Batch 1/3 Cost: 2.605781078338623\n",
      "Epoch 19/20 Batch 2/3 Cost: 2.2750394344329834\n",
      "Epoch 19/20 Batch 3/3 Cost: 5.667038440704346\n",
      "Epoch 20/20 Batch 1/3 Cost: 7.114394187927246\n",
      "Epoch 20/20 Batch 2/3 Cost: 2.944798707962036\n",
      "Epoch 20/20 Batch 3/3 Cost: 1.3891077041625977\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        # print(batch_idx)\n",
    "        # print(samples)\n",
    "        x_train, y_train = samples\n",
    "        # H(x) 계산\n",
    "        prediction = model(x_train)\n",
    "\n",
    "        # cost 계산\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "        # cost로 H(x) 계산\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch {epoch}/{nb_epochs} Batch {batch_idx+1}/{len(dataloader)} Cost: {cost.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:21:06.476569Z",
     "start_time": "2020-04-06T10:21:06.469588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[154.8488]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 [73, 80, 75]를 선언\n",
    "new_var =  torch.FloatTensor([[73, 80, 75]]) \n",
    "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var) \n",
    "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.8 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출처 : https://github.com/Namsik-Yoon/pytorch_basic/blob/master/2_1_%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80_with_My_data.ipynb\n",
    "\n",
    "boston 데이터셋을 바탕으로 활용해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:21:10.232567Z",
     "start_time": "2020-04-06T10:21:09.242194Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:21:10.998496Z",
     "start_time": "2020-04-06T10:21:10.986531Z"
    }
   },
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:21:11.735525Z",
     "start_time": "2020-04-06T10:21:11.714597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df = pd.DataFrame(data=boston['data'], columns=boston['feature_names'])\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보스턴 주택 가격 데이터는 다음과 같이 구성되어 있다.\n",
    "\n",
    "1. 타겟 데이터\n",
    "\n",
    "1978 보스턴 주택 가격\n",
    "\n",
    "506개 타운의 주택 가격 중앙값 (단위 1,000 달러)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 특징 데이터\n",
    "\n",
    "CRIM: 범죄율\n",
    "\n",
    "ZN: 25,000 평방피트를 초과 거주지역 비율\n",
    "\n",
    "INDUS: 비소매상업지역 면적 비율\n",
    "\n",
    "CHAS: 찰스강의 경계에 위치한 경우는 1, 아니면 0\n",
    "\n",
    "NOX: 일산화질소 농도\n",
    "\n",
    "RM: 주택당 방 수\n",
    "\n",
    "AGE: 1940년 이전에 건축된 주택의 비율\n",
    "\n",
    "DIS: 직업센터의 거리\n",
    "\n",
    "RAD: 방사형 고속도로까지의 거리\n",
    "\n",
    "TAX: 재산세율\n",
    "\n",
    "B: 인구 중 흑인 비율\n",
    "\n",
    "PTRATIO: 학생/교사 비율\n",
    "\n",
    "LSTAT: 인구 중 하위 계층 비율\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:21:13.699272Z",
     "start_time": "2020-04-06T10:21:13.659368Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419367</td>\n",
       "      <td>0.284548</td>\n",
       "      <td>-1.286636</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.144075</td>\n",
       "      <td>0.413263</td>\n",
       "      <td>-0.119895</td>\n",
       "      <td>0.140075</td>\n",
       "      <td>-0.981871</td>\n",
       "      <td>-0.665949</td>\n",
       "      <td>-1.457558</td>\n",
       "      <td>0.440616</td>\n",
       "      <td>-1.074499</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.416927</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>-0.592794</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.739530</td>\n",
       "      <td>0.194082</td>\n",
       "      <td>0.366803</td>\n",
       "      <td>0.556609</td>\n",
       "      <td>-0.867024</td>\n",
       "      <td>-0.986353</td>\n",
       "      <td>-0.302794</td>\n",
       "      <td>0.440616</td>\n",
       "      <td>-0.491953</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.416929</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>-0.592794</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.739530</td>\n",
       "      <td>1.281446</td>\n",
       "      <td>-0.265549</td>\n",
       "      <td>0.556609</td>\n",
       "      <td>-0.867024</td>\n",
       "      <td>-0.986353</td>\n",
       "      <td>-0.302794</td>\n",
       "      <td>0.396035</td>\n",
       "      <td>-1.207532</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416338</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>-1.305586</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.834458</td>\n",
       "      <td>1.015298</td>\n",
       "      <td>-0.809088</td>\n",
       "      <td>1.076671</td>\n",
       "      <td>-0.752178</td>\n",
       "      <td>-1.105022</td>\n",
       "      <td>0.112920</td>\n",
       "      <td>0.415751</td>\n",
       "      <td>-1.360171</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412074</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>-1.305586</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.834458</td>\n",
       "      <td>1.227362</td>\n",
       "      <td>-0.510674</td>\n",
       "      <td>1.076671</td>\n",
       "      <td>-0.752178</td>\n",
       "      <td>-1.105022</td>\n",
       "      <td>0.112920</td>\n",
       "      <td>0.440616</td>\n",
       "      <td>-1.025487</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.419367  0.284548 -1.286636 -0.272329 -0.144075  0.413263 -0.119895   \n",
       "1 -0.416927 -0.487240 -0.592794 -0.272329 -0.739530  0.194082  0.366803   \n",
       "2 -0.416929 -0.487240 -0.592794 -0.272329 -0.739530  1.281446 -0.265549   \n",
       "3 -0.416338 -0.487240 -1.305586 -0.272329 -0.834458  1.015298 -0.809088   \n",
       "4 -0.412074 -0.487240 -1.305586 -0.272329 -0.834458  1.227362 -0.510674   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  Price  \n",
       "0  0.140075 -0.981871 -0.665949 -1.457558  0.440616 -1.074499   24.0  \n",
       "1  0.556609 -0.867024 -0.986353 -0.302794  0.440616 -0.491953   21.6  \n",
       "2  0.556609 -0.867024 -0.986353 -0.302794  0.396035 -1.207532   34.7  \n",
       "3  1.076671 -0.752178 -1.105022  0.112920  0.415751 -1.360171   33.4  \n",
       "4  1.076671 -0.752178 -1.105022  0.112920  0.440616 -1.025487   36.2  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = boston_df.apply(lambda x: (x - x.mean()) / x.std())\n",
    "data['Price'] = boston['target']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:21:15.665006Z",
     "start_time": "2020-04-06T10:21:15.659023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506, 1)\n"
     ]
    }
   ],
   "source": [
    "X = data.values[:,:-1] # 모두 가져오는데 마지막만 제외하고\n",
    "y = data.values[:,-1:] # 모두 가져오는데 마지막만 가져온다.\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:21:16.985477Z",
     "start_time": "2020-04-06T10:21:16.980497Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:21:17.912998Z",
     "start_time": "2020-04-06T10:21:17.907014Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset): \n",
    "    # 데이터셋의 전처리를 해주는 부분\n",
    "    def __init__(self):\n",
    "        self.x_data = torch.tensor(X,dtype=torch.float)\n",
    "        self.y_data = torch.tensor(y,dtype=torch.float)\n",
    "        \n",
    "    # 데이터셋의 길이, 즉 총 샘플의 수를 적어주는 부분\n",
    "    def __len__(self): \n",
    "        return len(self.x_data)\n",
    "\n",
    "    # 데이터셋에서 특정 1개의 샘플을 가져오는 함수\n",
    "    def __getitem__(self, idx): \n",
    "        x = self.x_data[idx]\n",
    "        y = self.y_data[idx]\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:21:19.406030Z",
     "start_time": "2020-04-06T10:21:19.402048Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = MyDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:21:20.199884Z",
     "start_time": "2020-04-06T10:21:20.193924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404 102\n",
      "404 102\n"
     ]
    }
   ],
   "source": [
    "# train, validation set 나누기\n",
    "\n",
    "train_val_ratio = 0.8\n",
    "train_size = int(len(dataset) * train_val_ratio)\n",
    "val_size = len(dataset) - train_size\n",
    "print(train_size, val_size)\n",
    "\n",
    "#datset를 train_size와 val_size의 길이로 나눈다\n",
    "train_dataset,val_dataset = torch.utils.data.random_split(dataset,[train_size, val_size])\n",
    "print(len(train_dataset), len(val_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:21:20.895055Z",
     "start_time": "2020-04-06T10:21:20.891035Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=len(train_dataset), shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=len(val_dataset), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:21:22.252436Z",
     "start_time": "2020-04-06T10:21:21.746749Z"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Linear(13,1)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05)\n",
    "\n",
    "nb_epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    for samples in train_loader:\n",
    "        x_train, y_train = samples\n",
    "        \n",
    "        # H(x) 계산\n",
    "        prediction = model(x_train)\n",
    "\n",
    "        # cost 계산\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "        # cost로 H(x) 계산\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(cost.item())\n",
    "\n",
    "        #print(f'Epoch {epoch}/{nb_epochs} Cost: {cost.item()}')\n",
    "        \n",
    "    for samples in val_loader:\n",
    "        x_test, y_test = samples\n",
    "        prediction = model(x_test)\n",
    "        cost = F.mse_loss(prediction, y_test)\n",
    "        val_losses.append(cost.item())\n",
    "        #print(f'Validation Cost : {cost.item()}')\n",
    "    #print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T10:21:23.624728Z",
     "start_time": "2020-04-06T10:21:23.210835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses,label='train')\n",
    "plt.plot(val_losses,label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
