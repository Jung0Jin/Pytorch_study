{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.소프트맥스회귀.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM8AHx5ix3FHamOL1OEVkXp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jung0Jin/Pytorch_study/blob/master/4.%EC%86%8C%ED%94%84%ED%8A%B8%EB%A7%A5%EC%8A%A4%ED%9A%8C%EA%B7%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiqLac1VzHi6",
        "colab_type": "text"
      },
      "source": [
        "출처 : https://wikidocs.net/59425\n",
        "\n",
        "참고 : https://github.com/Namsik-Yoon/pytorch_basic/blob/master/4.%20%EC%86%8C%ED%94%84%ED%8A%B8%EB%A7%A5%EC%8A%A4%20%ED%9A%8C%EA%B7%80(Softmax_Regression).ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqZ_SeA4zOEu",
        "colab_type": "text"
      },
      "source": [
        "#4. 소프트맥스 회귀(Softmax Regression)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZbsPYWh1YKY",
        "colab_type": "text"
      },
      "source": [
        "##4.1 원-핫 인코딩(One-Hot Encoding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AAvwowv-Zkm",
        "colab_type": "text"
      },
      "source": [
        "범주형 데이터를 처리할 때 레이블을 표현하는 방법인 원-핫 인코딩에 대해 배우자."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctf2Sgo9-cfo",
        "colab_type": "text"
      },
      "source": [
        "###4.1.1 원-핫 인코딩이란?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSmt9oTb1rKP",
        "colab_type": "text"
      },
      "source": [
        "원-핫 인코딩은 선택지의 개수만큼의 차원을 가지면서, 각 선택지의 인덱스에 해당하는 원소에 1, 나머지 원소는 0의 값을 가지도록 하는 표현 방법이다.\n",
        "\n",
        "예를 들어 강아지, 고양이, 냉장고가 있다하자.\n",
        "\n",
        "강아지 = [1, 0, 0]\n",
        "\n",
        "고양이 = [0, 1, 0]\n",
        "\n",
        "냉장고 = [0, 0, 1]\n",
        "\n",
        "로 표현하는게 원-핫 인코딩이다. 이 벡터들을 원-핫 벡터라고 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kVWqOEk-gl0",
        "colab_type": "text"
      },
      "source": [
        "###4.1.2 원-핫 벡터의 무작위성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtzT3hhw2MlC",
        "colab_type": "text"
      },
      "source": [
        "범주형 데이터가 각 데이터 간의 관계가 균등하다는 점에서 원-핫 벡터는 적절한 표현 방법이다.\n",
        "\n",
        "다중 클래스 분류 문제도 각 클래스 간의 관계가 균등하다는 점에서 적절한 표현 방법이다.\n",
        "\n",
        "예를 들어 강아지, 고양이, 냉장고를 정수 인코딩 (0, 1, 2) 으로  레이블 한다면, 강아지와 고양이 사이의 관계(1-0 = 1)가 강아지와 냉장고 사이의 관계(2-0 = 2)보다 가깝다고 생각될 수 있다.\n",
        "\n",
        "클래스 간의 관계가 균등하기 때문에 특정 클래스가 가깝다고 여겨지는 정수 인코딩보다 원-핫 인코딩이 클래스의 성질을 잘 표현했다고 할 수 있다.\n",
        "\n",
        "이걸 아래의 식인 MSE를 사용하여 확인해보자.\n",
        "\n",
        "$Loss\\ function = \\frac{1}{n} \\sum_i^{n} \\left(y_{i} - \\hat{y_{i}}\\right)^2$\n",
        "\n",
        "강아지, 고양이, 냉장고라는 3개의 클래스를 각각 0, 1, 2 로 정수 인코딩한다.\n",
        "\n",
        "실제값이 강아지, 예측값이 고양이면 MSE는 다음과 같다.\n",
        "\n",
        "$(1-0)^{2} = 1$\n",
        "\n",
        "실제값이 강아지, 예측값이 냉장고면 MSE는 다음과 같다.\n",
        "\n",
        "$(2-0)^{2} = 4$\n",
        "\n",
        "오차의 값이 다르다. 즉, 이는 기계에게 강아지가 냉장고보다 고양이에 가깝다는 정보를 주는 것과 다름 없다.\n",
        "\n",
        "더 많은 클래스에 대해 정수 인코딩을 수행하면? 난리난다.\n",
        "\n",
        "정리하겠다. 정수 인코딩과 달리 원-핫 인코딩은 분류 문제에서 모든 클래스 간의 관계를 균등하게 분배한다.\n",
        "\n",
        "원-핫 인코딩을 했을 때의 MSE를 보겠다.\n",
        "\n",
        "$((1,0,0)-(0,1,0))^{2} = (1-0)^{2} + (0-1)^{2} + (0-0)^{2} = 2$\n",
        "\n",
        "$((1,0,0)-(0,0,1))^{2} = (1-0)^{2} + (0-0)^{2} + (0-1)^{2} = 2$\n",
        "\n",
        "원-핫 인코딩은 클래스의 관계를 균등하기 만들기 때문에 원-핫벡터는 무작위성을 가진다. 각 클래스를 인코딩 할 때 표현 방법이 무작위하다는 것이다. 예를 들어 강아지가 (1,0,0) 일지 (0,1,0) 일지 (0,0,1) 일지 모른다. 이러한 원-핫 벡터의 무작위성은 때로는 단어의 유사성을 구할 수 없다는 단점으로 언급되기도 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pjlY2qp-ric",
        "colab_type": "text"
      },
      "source": [
        "## 4.2 소프트맥스 회귀 이해하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cOXMRLf5o-x",
        "colab_type": "text"
      },
      "source": [
        "로지스틱 회귀 : 2개 중 1개 고르는 이진 분류\n",
        "\n",
        "소프트맥스 회귀 : 3개 이상 중 1개 고르는 다증 클래스 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AjXQoMu-vbT",
        "colab_type": "text"
      },
      "source": [
        "###4.2.1 다중 클래스 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO2iqi7v8XjZ",
        "colab_type": "text"
      },
      "source": [
        "아래는 꽃받침 길이, 꽃받침 넓이, 꽃잎 길이, 꽃잎 넓이라는 4개의 특성(feature)로부터 setosa, versicolor, virginica 라는 3개의 붓꽃 품종을 예측하는 문제이다.\n",
        "\n",
        "|SepalLengthCm$(x_1)$|SepalWidthCm$(x_2)$|PetalLengthCm$(x_3)$|PetalWidthCm$(x_4)$|Species$(y)$|\n",
        "|---|---|---|---|---|\n",
        "|5.1|3.5|1.4|0.2|setosa|\n",
        "|4.9|3.0|1.4|0.2|setosa|\n",
        "|5.8|2.6|4.0|1.2|versicolor|\n",
        "|6.7|3.0|5.2|2.3|virginica|\n",
        "|5.6|2.8|4.9|2.0|virginica|\n",
        "\n",
        "이번 챕터의 설명에서 입력은 $X$, 가중치는 $W$, 편향은 $B$, 출력은 $\\hat{Y}$로 각 변수는 벡터 또는 행렬로 가정한다.\n",
        "\n",
        "*   $\\hat{Y}$은 예측값이라는 의미를 가지고 있으므로 가설식에서 $H(X)$ 대신 사용되기도 한다.\n",
        "\n",
        "1) 로지스틱 회귀\n",
        "\n",
        "로지스틱 회귀에서 시그모이드 함수는 예측값을 0과 1사이의 값으로 만든다.\n",
        "\n",
        "예를 들어 스팸 메일 분류기를 로지스틱 회귀로 구현하면, 출력이 0.75라면 스팸일 확률이 75%라는 의미가 된다. 동시에, 스팸이 아닐 확률이 25%가 된다.\n",
        "\n",
        "![대체 텍스트](https://camo.githubusercontent.com/acee24af0ee38fcf4de25f774073d702ad289194/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f35393432372f2545422541312539432545432541372538302545432538412541342545442538422542312545442539412538432545412542372538302e504e47)\n",
        "\n",
        "가설 : $H(X) = sigmoid(WX + B)$\n",
        "\n",
        "2) 소프트맥스 회귀\n",
        "\n",
        "소프트맥스 회귀에서 소프트맥스 함수는 예측값을 0과 1사이의 값으로 만든다.\n",
        "\n",
        "선택지의 개수만큼의 차원을 가지는 벡터를 만들고, 모든 원소의 합이 1이 되도록 원소들의 값을 변환시키는 소프트맥스 함수를 지나게 만들어야 한다.\n",
        "\n",
        "![대체 텍스트](https://camo.githubusercontent.com/2be4df15c4c65877caf65dced6533ed34009e39e/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f35393432372f2545432538362538432545442539342538342545442538412542382545422541372541352545432538412541342545442539412538432545412542372538302e504e47)\n",
        "\n",
        "가설 : $H(X) = softmax(WX + B)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E82Hebqi-4Ca",
        "colab_type": "text"
      },
      "source": [
        "###4.2.2 소프트맥스 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Idz6bGMl__cE",
        "colab_type": "text"
      },
      "source": [
        "소프트맥스 함수는 클래스의 개수(k라고 하자)만큼의 차원을 가진 벡터를 입력받아 각 클래스에 대한 확률을 추정한다.\n",
        "\n",
        "1) 소프트맥스 함수의 이해\n",
        "\n",
        "k차원의 벡터에서 i번째 원소를 $z_i$, i번째 클래스가 정답일 확률을 $p_i$로 나타낸다고 하였을 때 소프트맥스 함수는 $p_i$를 다음과 같이 정의한다.\n",
        "\n",
        "$p_{i}=\\frac{e^{z_{i}}}{\\sum_{j=1}^{k} e^{z_{j}}}\\ \\ for\\ i=1, 2, ... k$\n",
        "\n",
        "![대체 텍스트](https://camo.githubusercontent.com/2be4df15c4c65877caf65dced6533ed34009e39e/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f35393432372f2545432538362538432545442539342538342545442538412542382545422541372541352545432538412541342545442539412538432545412542372538302e504e47)\n",
        "\n",
        "위에서 풀어야하는 문제에 소프트맥스 함수를 차근차근 적용해보자. 문제의 경우 k=3이므로 3차원 벡터 $z=[z_{1}\\ z_{2}\\ z_{3}]$의 입력을 받으면 소프트맥스 함수는 아래와 같은 출력을 리턴한다.\n",
        "\n",
        "$softmax(z)=[\\frac{e^{z_{1}}}{\\sum_{j=1}^{3} e^{z_{j}}}\\ \\frac{e^{z_{2}}}{\\sum_{j=1}^{3} e^{z_{j}}}\\ \\frac{e^{z_{3}}}{\\sum_{j=1}^{3} e^{z_{j}}}] = [p_{1}, p_{2}, p_{3}] = \\hat{y} = \\text{예측값}$\n",
        "\n",
        "$p_1,p_2,p_3$  각각은 1번 클래스가 정답일 확률, 2번 클래스가 정답일 확률, 3번 클래스가 정답일 확률을 나타내며 각각 0과 1사이의 값으로 총 합은 1이 된다.\n",
        "\n",
        "여기서 분류하고자하는 3개의 클래스는 virginica, setosa, versicolor이므로 이는 결국 주어진 입력이 virginica일 확률, setosa일 확률, versicolor일 확률을 나타내는 값을 의미한다.\n",
        "\n",
        "여기서는 i가 1일 때는 virginica일 확률을 나타내고, 2일 때는 setosa일 확률, 3일때는 versicolor일 확률이라고 지정하였다고 하자. 이 지정 순서는 문제를 풀고자 하는 사람의 무작위 선택이다. 이에따라 식을 문제에 맞게 다시 쓰면 아래와 같다.\n",
        "\n",
        "$softmax(z)=[\\frac{e^{z_{1}}}{\\sum_{j=1}^{3} e^{z_{j}}}\\ \\frac{e^{z_{2}}}{\\sum_{j=1}^{3} e^{z_{j}}}\\ \\frac{e^{z_{3}}}{\\sum_{j=1}^{3} e^{z_{j}}}] = [p_{1}, p_{2}, p_{3}] = [p_{virginica}, p_{setosa}, p_{versicolor}]$\n",
        "\n",
        "정리 : 분류하고자 하는 클래스가 k개이면, k차원의 벡터를 입력받아서 벡터의 모든 원소의 값을 0과 1사이의 값으로 변경하고, 다시 k차원의 벡터를 리턴하면 된다.\n",
        "\n",
        "2) 그림을 통한 이해\n",
        "\n",
        "![](https://camo.githubusercontent.com/a6ede60782b3f8d590aca00e9e765ea5ec732afb/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f33353437362f736f66746d6178315f66696e616c5f66696e616c2e504e47)\n",
        "\n",
        "질문 1 : 샘플 데이터를 소프트맥스 함수의 입력으로 어떻게 바꿀까?\n",
        "\n",
        "|SepalLengthCm$(x_1)$|SepalWidthCm$(x_2)$|PetalLengthCm$(x_3)$|PetalWidthCm$(x_4)$|Species$(y)$|\n",
        "|---|---|---|---|---|\n",
        "|5.1|3.5|1.4|0.2|setosa|\n",
        "|4.9|3.0|1.4|0.2|setosa|\n",
        "|5.8|2.6|4.0|1.2|versicolor|\n",
        "|6.7|3.0|5.2|2.3|virginica|\n",
        "|5.6|2.8|4.9|2.0|virginica|\n",
        "\n",
        "여기서 샘플 데이터를 1개씩 입력으로 받아 처리한다고 가정하자. 샘플 데이터가 1개씩 처리된다는 것은 배치 크기가 1이라는 것과 같은 의미다. 하나의 샘플 데이터는 4개의 독립 변수 $x$를 가지는데 이는 모델이 4차원 벡터를 입력으로 받음을 의미한다.\n",
        "\n",
        "4차원 벡터가 모델로 입력된 다음 단계는 소프트맥스 함수에 입력되는 것이다.\n",
        "\n",
        "모델에 입력된 벡터는 4차원이고, 소프트맥스 함수에 입력될 수 있는 벡터는 3차원이다.\n",
        "\n",
        "따라서, 입력된 4차원 벡터는 다시 어떤 가중치 연산을 통해 분류하고자 하는 클래스의 개수인 3차원 벡터로 변환되어야 한다. \n",
        "\n",
        "그래야 소프트맥스 함수의 입력으로 쓸 수 있다.\n",
        "\n",
        "아래 그림에서는 소프트맥스 함수의 입력으로 사용되는 3차원 벡터를 $z$로 표현했다.\n",
        "\n",
        "![](https://camo.githubusercontent.com/172a4d05ef2b15ec46c642dc195caf7fa97f047b/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f33353437362f736f66746d61786265747765656e31616e64322e504e47)\n",
        "\n",
        "샘플 데이터 벡터(4차원)를 소프트맥스 함수의 입력 벡터(3차원)로 변환하는 방법은 소프트맥스 함수의 입력 벡터 $z$의 차원수만큼 결과값이 나오도록 가중치 곱을 진행하는 것이다.\n",
        "\n",
        "즉 (4 x 3 = 12) 12개의 전부 다른 가중치로 학습 과정에서 점차적으로 오차를 최소화하면 된다.\n",
        "\n",
        "질문 2 : 오차를 어떻게 구할까?\n",
        "\n",
        "여기서는 첫번째 원소인 $p_1$은 virginica가 정답일 확률, 두번째 원소인 $p_2$는 setosa가 정답일 확률, 세번째 원소인 $p_3$은 versicolor가 정답일 확률로 고려한다. 그렇다면 이 예측값과 비교를 할 수 있는 실제값의 표현 방법이 있어야 한다. 소프트맥스 회귀에서는 실제값을 원-핫 벡터로 표현한다. 아래 그림은 원-핫 인코딩을 수행하여 실제값을 원-핫 벡터로 수치화한 것을 보여준다.\n",
        "\n",
        "![](https://camo.githubusercontent.com/e57ce45ea8db9548650e711170568fd662b3d067/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f33353437362f736f66746d6178325f66696e616c2e504e47)\n",
        "\n",
        "현재 풀고 있는 샘플 데이터의 실제값이 setosa라면 setosa의 원-핫 벡터는 [0,1,0]이다. 이 두 벡터의 오차를 계산하기 위해서 소프트맥스 회귀는 비용 함수로 크로스 엔트로피 함수를 사용한다.\n",
        "\n",
        "![](https://camo.githubusercontent.com/5af606fdacad2a5d610b760eaad071314945e153/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f33353437362f736f66746d6178342e504e47)\n",
        "\n",
        "![](https://camo.githubusercontent.com/b07ec8f666e2c2e3490c7f6a0da57a3ad3d5701e/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f33353437362f736f66746d6178352e504e47)\n",
        "\n",
        "![](https://camo.githubusercontent.com/92fb01a7238490aad23863f2b331ffdcc9ccba0b/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f33353437362f736f66746d6178365f66696e616c2e504e47)\n",
        "\n",
        "이런식으로 앞서 배운 선형 회귀나 로지스틱 회귀와 마찬가지로 오차로부터 가중치를 업데이트 한다.\n",
        "\n",
        "소프트맥스 회구를 벡터와 행렬 연산으로 이해해보자. \n",
        "\n",
        "입력 : 특성(feature)의 수만큼의 차원을 가진 입력 벡터 $x$\n",
        "\n",
        "가중치 :  $W$\n",
        "\n",
        "편향 : $B$\n",
        "\n",
        "소프트맥스 회귀에서 예측값을 구하는 과정을 벡터와 행렬 연산으로 표현하면 아래와 같다.\n",
        "\n",
        "![](https://camo.githubusercontent.com/713e4d3501b73cb09e2d8ff1550ce3f08e719bc1/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f35393432372f2545412542302538302545432538342541342e504e47)\n",
        "\n",
        "$f$는 특성의 수, $c$는 클래스의 개수이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZaMLOYP_MfU",
        "colab_type": "text"
      },
      "source": [
        "###4.2.3 붓꽃 품종 분류를 행렬 연산으로 이해하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9xn8tNaLm7f",
        "colab_type": "text"
      },
      "source": [
        "|SepalLengthCm$(x_1)$|SepalWidthCm$(x_2)$|PetalLengthCm$(x_3)$|PetalWidthCm$(x_4)$|Species$(y)$|\n",
        "|---|---|---|---|---|\n",
        "|5.1|3.5|1.4|0.2|setosa|\n",
        "|4.9|3.0|1.4|0.2|setosa|\n",
        "|5.8|2.6|4.0|1.2|versicolor|\n",
        "|6.7|3.0|5.2|2.3|virginica|\n",
        "|5.6|2.8|4.9|2.0|virginica|\n",
        "\n",
        "우선 위 예제 데이터는 샘플의 수 5개, 특성의 수 4개로 5 x 4 행렬 $X$로 정의하자\n",
        "\n",
        "$X=\n",
        "\\left(\n",
        "    \\begin{array}{c}\n",
        "      5.1\\ 3.5\\ 1.4\\ 0.2\\ \\\\\n",
        "      4.9\\ 3.0\\ 1.4\\ 0.2\\ \\\\\n",
        "      5.8\\ 2.6\\ 4.0\\ 1.2\\ \\\\\n",
        "      6.7\\ 3.0\\ 5.2\\ 2.3\\ \\\\\n",
        "      5.6\\ 2.8\\ 4.9\\ 2.0\\ \\\\\n",
        "    \\end{array}\n",
        "  \\right)$\n",
        "\n",
        "각 행렬의 원소 위치를 반영한 변수로 표현하면\n",
        "\n",
        "$X=\\left(\n",
        "    \\begin{array}{c}\n",
        "      x_{11}\\ x_{12}\\ x_{13}\\ x_{14}\\ \\\\\n",
        "      x_{21}\\ x_{22}\\ x_{23}\\ x_{24}\\ \\\\\n",
        "      x_{31}\\ x_{32}\\ x_{33}\\ x_{34}\\ \\\\\n",
        "      x_{41}\\ x_{42}\\ x_{43}\\ x_{44}\\ \\\\\n",
        "      x_{51}\\ x_{52}\\ x_{53}\\ x_{54}\\ \\\\\n",
        "    \\end{array}\n",
        "  \\right)$\n",
        "\n",
        "  이 문제는 선택지가 총 3개인 문제이므로 (=클래스가 총 3개인 문제이므로) 가설의 예측값으로 얻는 행렬 $\\hat{Y}$의 열의 개수는 3개여야 한다. 각 행은 행렬 $X$의 각 행의 예측값이므로 행의 개수는 5개로 동일해야 한다. 행렬 $\\hat{Y}$의 크기는 5 × 3 이다.\n",
        "\n",
        "$\\hat{Y}=\\left(\n",
        "    \\begin{array}{c}\n",
        "      y_{11}\\ y_{12}\\ y_{13}\\ \\\\\n",
        "      y_{21}\\ y_{22}\\ y_{23}\\ \\\\\n",
        "      y_{31}\\ y_{32}\\ y_{33}\\ \\\\\n",
        "      y_{41}\\ y_{42}\\ y_{43}\\ \\\\\n",
        "      y_{51}\\ y_{52}\\ y_{53}\\ \\\\\n",
        "    \\end{array}\n",
        "  \\right)$\n",
        "\n",
        "크기 5 × 3의 행렬 $\\hat{Y}$는 \n",
        "\n",
        "크기 5 × 4 입력 행렬 $X$와 \n",
        "\n",
        "가중치 행렬 $W$의 곱으로 얻어지는 행렬이므로 \n",
        "\n",
        "가중치 행렬 $W$은 4 × 3의 크기를 가진 행렬임을 알 수 있다.\n",
        "\n",
        "$W=\\left(\n",
        "    \\begin{array}{c}\n",
        "      w_{11}\\ w_{12}\\ w_{13}\\ \\\\\n",
        "      w_{21}\\ w_{22}\\ w_{23}\\ \\\\\n",
        "      w_{31}\\ w_{32}\\ w_{33}\\ \\\\\n",
        "      w_{41}\\ w_{42}\\ w_{43}\\ \\\\\n",
        "    \\end{array}\n",
        "  \\right)$\n",
        "\n",
        "편향 행렬 $B$는 예측값 행렬 $\\hat{Y}$와 크기가 동일해야 하므로 5 × 3의 크기를 가진다.\n",
        "\n",
        "$B=\\left(\n",
        "    \\begin{array}{c}\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\n",
        "    \\end{array}\n",
        "  \\right)$\n",
        "\n",
        "결과적으로 가설식은 다음과 같다.\n",
        "\n",
        "$\\hat{Y} = softmax(XW + B)$\n",
        "\n",
        "$\\left(\n",
        "    \\begin{array}{c}\n",
        "      y_{11}\\ y_{12}\\ y_{13}\\ \\\\\n",
        "      y_{21}\\ y_{22}\\ y_{23}\\ \\\\\n",
        "      y_{31}\\ y_{32}\\ y_{33}\\ \\\\\n",
        "      y_{41}\\ y_{42}\\ y_{43}\\ \\\\\n",
        "      y_{51}\\ y_{52}\\ y_{53}\\ \\\\\n",
        "    \\end{array}\n",
        "  \\right)$=$softmax\\left(\n",
        "\\left(\n",
        "    \\begin{array}{c}\n",
        "      x_{11}\\ x_{12}\\ x_{13}\\ x_{14}\\ \\\\\n",
        "      x_{21}\\ x_{22}\\ x_{23}\\ x_{24}\\ \\\\\n",
        "      x_{31}\\ x_{32}\\ x_{33}\\ x_{34}\\ \\\\\n",
        "      x_{41}\\ x_{42}\\ x_{43}\\ x_{44}\\ \\\\\n",
        "      x_{51}\\ x_{52}\\ x_{53}\\ x_{54}\\ \\\\\n",
        "    \\end{array}\n",
        "  \\right)\n",
        "\\left(\n",
        "    \\begin{array}{c}\n",
        "      w_{11}\\ w_{12}\\ w_{13}\\ \\\\\n",
        "      w_{21}\\ w_{22}\\ w_{23}\\ \\\\\n",
        "      w_{31}\\ w_{32}\\ w_{33}\\ \\\\\n",
        "      w_{41}\\ w_{42}\\ w_{43}\\ \\\\\n",
        "    \\end{array}\n",
        "  \\right)\n",
        "+\n",
        "\\left(\n",
        "    \\begin{array}{c}\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\n",
        "    \\end{array}\n",
        "  \\right)\n",
        "\\right)$\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVL1KM2g_RvG",
        "colab_type": "text"
      },
      "source": [
        "###4.2.4 비용 함수\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co4EJyCWNXLP",
        "colab_type": "text"
      },
      "source": [
        "소프트맥스 회귀에서는 비용 함수로 크로스 엔트로피 함수를 사용한다.\n",
        "\n",
        "1) 크로스 엔트로피 함수\n",
        "\n",
        "$y$ : 실제값\n",
        "\n",
        "$k$ : 클래스의 개수\n",
        "\n",
        "$y_j$ : 실제값 원-핫 벡터의 $j$번째 인덱스를 의미\n",
        "\n",
        "$p_j$ : 샘플 데이터가 $j$번째 클래스일 확률 ($\\hat{y}_{j}$로 표현하기도 한다.)\n",
        "\n",
        "$cost(W) = -\\sum_{j=1}^{k}y_{j}\\ log(p_{j})$\n",
        "\n",
        "$c$가 실제값 원-핫 벡터에서 1을 가진 원소의 인덱스라고 한다면, $p_{c}=1$은 $\\hat{y}$가 $y$를 정확하게 예측한 경우가 된다.\n",
        "\n",
        "이를 식에 대입해보면 $-1 log(1) = 0$이 되기 때문에, 결과적으로 $\\hat{y}$가 $y$를 정확하게 예측한 경우의 크로스 엔트로피 함수의 값은 0이 된다. 즉, $-\\sum_{j=1}^{k}y_{j}\\ log(p_{j})$ 이 값을 최소화하는 방향으로 학습해야 한다.\n",
        "\n",
        "이제 이를 $n$개의 전체 데이터에 대한 평균을 구한다고 하면 최종 비용 함수는 다음과 같다.\n",
        "\n",
        "$cost(W) = -\\frac{1}{n} \\sum_{i=1}^{n} \\sum_{j=1}^{k}y_{j}^{(i)}\\ log(p_{j}^{(i)})$\n",
        "\n",
        "2) 이진 분류에서의 크로스 엔트로피 함수\n",
        "\n",
        "로지스틱 회귀에서 배운 크로스 엔트로피 함수식과 달라보이지만, 본질적으로는 동일한 함수식이다. 로지스틱 회귀의 크로스 엔트로피 함수식으로부터 소프트맥스 회귀의 크로스 엔트로피 함수식을 도출해보자.\n",
        "\n",
        "$cost(W) = -(y\\ logH(X) + (1-y)\\ log(1-H(X)))$\n",
        "\n",
        "위의 식은 앞서 로지스틱 회귀에서 배웠던 크로스 엔트로피의 함수식을 보여준다. 위의 식에서 $y$를 $y_1$, $y$−1을 $y_2$로 치환하고 $H(X)$를 $p_1$, 1−$H(X)$를 $p_2$로 치환하면 결과적으로 아래의 식을 얻을 수 있습니다.\n",
        "\n",
        "$-(y_{1}\\ log(p_{1})+y_{2}\\ log(p_{2}))$\n",
        "\n",
        "이 식은 아래와 같이 표현할 수 있다.\n",
        "\n",
        "$-(\\sum_{i=1}^{2}y_{i}\\ log\\ p_{i})$\n",
        "\n",
        "소프트맥스 회귀에서는 k의 값이 고정된 값이 아니므로 2를 k로 변경하면\n",
        "\n",
        "$-(\\sum_{i=1}^{k}y_{i}\\ log\\ p_{i})$\n",
        "\n",
        "위의 식은 결과적으로 소프트맥스 회귀의 식과 동일하다. 역으로 소프트맥스 회귀에서 로지스틱 회귀의 크로스 엔트로피 함수식을 얻는 것은 k를 2로 하고, $y_1$과 $y_2$를 각각 $y$와 1−$y$로 치환하고, $p_1$와 $p_2$를 각각 $H(X)$와 1−$H(X)$로 치환하면 된다.\n",
        "\n",
        "정리하면 소프트맥스 함수의 최종 비용 함수에서 $k$가 2라고 가정하면 결국 로지스틱 회귀의 비용 함수와 같다.\n",
        "\n",
        "$cost(W) = -\\frac{1}{n} \\sum_{i=1}^{n} \\sum_{j=1}^{k}y_{j}^{(i)}\\ log(p_{j}^{(i)}) = -\\frac{1}{n} \\sum_{i=1}^{n} [y^{(i)}log(p^{(i)}) + (1-y^{(i)})log(1-p^{(i)})]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQXJtJPfPIkw",
        "colab_type": "text"
      },
      "source": [
        "##4.3 소프트맥스 회귀의 비용 함수 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uI00zK--j2s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8ded83ce-3679-4fd4-acf4-d73f81e2f770"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f60b71de0d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW99WqNFPf5C",
        "colab_type": "text"
      },
      "source": [
        "###4.3.1 파이토치로 소프트맥스 회귀의 비용 함수 구현하기 (로우-레벨)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjt_quHwPqtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = torch.FloatTensor([1,2,3])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYGaE_RzPwF2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "171e0101-ca59-4418-9d7d-4dbd5a863f18"
      },
      "source": [
        "hypothesis = F.softmax(z, dim=0)\n",
        "print(hypothesis)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0900, 0.2447, 0.6652])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "argQp_reP9l6",
        "colab_type": "text"
      },
      "source": [
        "$p_{i}=\\frac{e^{z_{i}}}{\\sum_{j=1}^{k} e^{z_{j}}}\\ \\ for\\ i=1, 2, ... k$\n",
        "\n",
        "$softmax(z)=[\\frac{e^{z_{1}}}{\\sum_{j=1}^{3} e^{z_{j}}}\\ \\frac{e^{z_{2}}}{\\sum_{j=1}^{3} e^{z_{j}}}\\ \\frac{e^{z_{3}}}{\\sum_{j=1}^{3} e^{z_{j}}}] = [p_{1}, p_{2}, p_{3}] = \\hat{y} = \\text{예측값}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiKU3KQcQJu4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "183ad47a-18b8-4f92-acb0-c2edb314cdb6"
      },
      "source": [
        "hypothesis.sum()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2lFJ8YHQM-W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "14bfa703-6ae8-4021-cf35-82f40d7c7147"
      },
      "source": [
        "z = torch.rand(3, 5, requires_grad=True)\n",
        "z"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7576, 0.2793, 0.4031, 0.7347, 0.0293],\n",
              "        [0.7999, 0.3971, 0.7544, 0.5695, 0.4388],\n",
              "        [0.6387, 0.5247, 0.6826, 0.3051, 0.4635]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWmHLo9tQS3p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "976dbfbd-6ed0-4dd4-9778-2cc429f55b85"
      },
      "source": [
        "hypothesis = F.softmax(z, dim=1) # 각 샘플에 대해 소프트맥스 함수를 적용해야 하므로, 두번째 차원에 대해 소프트맥스 함수를 적용한다는 의미로, dim=1\n",
        "print(hypothesis)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2645, 0.1639, 0.1855, 0.2585, 0.1277],\n",
            "        [0.2430, 0.1624, 0.2322, 0.1930, 0.1694],\n",
            "        [0.2226, 0.1986, 0.2326, 0.1594, 0.1868]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJBth7-dQ1JF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "aba391c8-bc48-4636-aa68-2a733580d827"
      },
      "source": [
        "# 소프트맥스 함수의 출력값은 결국 예측값이고, 확률이다. 합은 1이다.\n",
        "print(hypothesis[0,:].sum())\n",
        "print(hypothesis[1,:].sum())\n",
        "print(hypothesis[2,:].sum())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.0000, grad_fn=<SumBackward0>)\n",
            "tensor(1.0000, grad_fn=<SumBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWYXy9eYQlZo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "30a470da-4fe9-425b-befd-cf81ed17fcd8"
      },
      "source": [
        "# 각 샘플에 대해 임의의 레이블을 만든다.\n",
        "y = torch.randint(5, (3,)).long()\n",
        "print(y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 2, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFu-kiyoRkAe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a02d2acf-8201-4192-8e0a-11dcf0e21e66"
      },
      "source": [
        "# 각 레이블에 대해 원-핫 인코딩을 수행한다.\n",
        "# 모든 원소가 0의 값을 가진 3 × 5 텐서 생성\n",
        "y_one_hot = torch.zeros_like(hypothesis) # hypothesis와 같은 크기를 가지고 모든 원소가 0의 값을 가지는 텐서를 만들어라.\n",
        "y_one_hot.scatter_(1, y.unsqueeze(1), 1)\n",
        "\"\"\"\n",
        "y.unsqueeze(1)에서 (3,)의 크기를 가졌던 y텐서는 (3x1) 텐서가 된다. \n",
        "scatter의 첫번째 인자는 dim=1 에 대해 수행하라는 의미\n",
        "세번째 인자에 1을 넣어줌으로서 두번째 인자인 y_unsqueeze(1)이 알려주는 위치에 숫자 1을 넣도록 한다.\n",
        "연산 뒤에 _를 붙이면 In-place Operation (덮어쓰기 연산) 이다.\n",
        "\"\"\"\n",
        "print(y_one_hot)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJUboO4PRjZp",
        "colab_type": "text"
      },
      "source": [
        "$cost(W) = -\\frac{1}{n} \\sum_{i=1}^{n} \\sum_{j=1}^{k}y_{j}^{(i)}\\ log(p_{j}^{(i)})$\n",
        "\n",
        "마이너스 부호를 뒤로 빼면 다음 식과도 동일하다.\n",
        "\n",
        "$cost(W) = \\frac{1}{n} \\sum_{i=1}^{n} \\sum_{j=1}^{k}y_{j}^{(i)}\\ * (-log(p_{j}^{(i)}))$\n",
        "\n",
        "이를 코드로 구현하면 아래와 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCAP66H8TibI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "31396f31-dcaf-49d8-af8e-0847af626724"
      },
      "source": [
        "cost = (y_one_hot * -torch.log(hypothesis)).sum(dim=1).mean()\n",
        "print(cost)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.4689, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNtj6r9lPl1G",
        "colab_type": "text"
      },
      "source": [
        "###4.3.2 파이토치로 소프트맥스 회귀의 비용 함수 구현하기 (하이-레벨)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qq4hGNT_eaE",
        "colab_type": "text"
      },
      "source": [
        "1)  F.softmax() + torch.log() = F.log_softmax()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83m5A86C0KIR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ccd9e71c-6d4c-4401-8985-3874c6130158"
      },
      "source": [
        "# Low level\n",
        "torch.log(F.softmax(z, dim=1))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.3301, -1.8084, -1.6846, -1.3530, -2.0584],\n",
              "        [-1.4147, -1.8174, -1.4602, -1.6450, -1.7758],\n",
              "        [-1.5025, -1.6165, -1.4586, -1.8360, -1.6776]], grad_fn=<LogBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUCw8pSQT1in",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "a07289fb-52a9-4790-a5e6-659127a1ee69"
      },
      "source": [
        "# High level\n",
        "F.log_softmax(z, dim=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.3301, -1.8084, -1.6846, -1.3530, -2.0584],\n",
              "        [-1.4147, -1.8174, -1.4602, -1.6450, -1.7758],\n",
              "        [-1.5025, -1.6165, -1.4586, -1.8360, -1.6776]],\n",
              "       grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSVIHOMLT6hV",
        "colab_type": "text"
      },
      "source": [
        "2) F.log_softmax() + F.nll_loss() = F.cross_entropy()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGkmfU8wT2sv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9fe90d98-ea9a-4e8a-c3a1-c1887aea4356"
      },
      "source": [
        "# Low level\n",
        "# 첫번째 수식\n",
        "(y_one_hot * -torch.log(F.softmax(z, dim=1))).sum(dim=1).mean()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.4689, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV87suPGT84k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7a4dcbcb-3fcf-4d49-cd17-855757e77648"
      },
      "source": [
        "# 두번째 수식\n",
        "(y_one_hot * - F.log_softmax(z, dim=1)).sum(dim=1).mean()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.4689, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zBUtKIpUCQm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eb224b6b-d5a2-4c91-d8f4-52568039fd95"
      },
      "source": [
        "# High level\n",
        "# 세번째 수식\n",
        "F.nll_loss(F.log_softmax(z, dim=1), y)\n",
        "# nll : Negative Log Likelihood의 약자"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.4689, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVP6uhC4UQm2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c07560de-67af-43a8-8a3f-dc07f6bdc631"
      },
      "source": [
        "# 네번째 수식\n",
        "F.cross_entropy(z, y)\n",
        "# 비용 함수에 소프트맥스 함수까지 포함하고 있음을 기억하고 있어야 구현 시 혼동하지 않는다."
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.4689, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnZtyablUjp5",
        "colab_type": "text"
      },
      "source": [
        "##4.4 소프트맥스 회귀 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_orNmGiUSVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jfq-YJKzUt2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "x_train : 8 x 4 \n",
        "y_trian : 8 x 1, 3개의 클래스\n",
        "\"\"\"\n",
        "\n",
        "x_train = [[1, 2, 1, 1],\n",
        "           [2, 1, 3, 2],\n",
        "           [3, 1, 3, 4],\n",
        "           [4, 1, 5, 5],\n",
        "           [1, 7, 5, 5],\n",
        "           [1, 2, 5, 6],\n",
        "           [1, 6, 6, 6],\n",
        "           [1, 7, 7, 7]]\n",
        "y_train = [2, 2, 2, 1, 1, 1, 0, 0]\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "y_train = torch.LongTensor(y_train)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktlGJJvCVGpg",
        "colab_type": "text"
      },
      "source": [
        "###4.4.1 소프트맥스 회귀 구현하기(로우-레벨)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4in7IZTiVBZO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5f6be89c-bdba-4e3f-f753-27dfa982f05f"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 4])\n",
            "torch.Size([8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXNE_EnNVNr1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f29aa29d-94b5-4333-de98-876db1baa005"
      },
      "source": [
        "# y_train은 원-핫 인코딩 시켜줘야 한다.\n",
        "y_one_hot = torch.zeros(8, 3)\n",
        "y_one_hot.scatter_(1, y_train.unsqueeze(1), 1)\n",
        "print(y_one_hot.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQGXHt12VZPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X가 8x4, Y가 8x3이므로 W는 4x3임을 추정할 수 있다.\n",
        "\n",
        "# 모델 초기화\n",
        "W = torch.zeros((4, 3), requires_grad=True)\n",
        "b = torch.zeros(3, requires_grad=True) # 선형 회귀, 로지스틱 회귀에서는 b가 1이지만 이제는 클래스 개수 만큼이다.\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=0.1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtBcfE55VpPG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "a92c5141-d79c-4bb5-8935-d2cf36ac3012"
      },
      "source": [
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # 가설\n",
        "    hypothesis = F.softmax(x_train.matmul(W) + b, dim=1) \n",
        "\n",
        "    # 비용 함수\n",
        "    cost = (y_one_hot * -torch.log(hypothesis)).sum(dim=1).mean()\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch}/{nb_epochs}, Cost: {cost.item()}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/1000, Cost: 1.0986123085021973\n",
            "Epoch 100/1000, Cost: 0.704199492931366\n",
            "Epoch 200/1000, Cost: 0.6229994893074036\n",
            "Epoch 300/1000, Cost: 0.5657168030738831\n",
            "Epoch 400/1000, Cost: 0.5152913928031921\n",
            "Epoch 500/1000, Cost: 0.467661589384079\n",
            "Epoch 600/1000, Cost: 0.42127782106399536\n",
            "Epoch 700/1000, Cost: 0.37540143728256226\n",
            "Epoch 800/1000, Cost: 0.3297658860683441\n",
            "Epoch 900/1000, Cost: 0.2850724756717682\n",
            "Epoch 1000/1000, Cost: 0.2481546401977539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u3w7nf7AGYP",
        "colab_type": "text"
      },
      "source": [
        "###4.4.2 소프트맥스 회귀 구현하기(하이-레벨)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NIfJ7wHV8II",
        "colab_type": "text"
      },
      "source": [
        "주의할 점은 F.cross_entropy()는 그 자체로 소프트맥스 함수를 포함하고 있다는 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyESSTi7V5bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 초기화\n",
        "W = torch.zeros((4, 3), requires_grad=True)\n",
        "b = torch.zeros(3, requires_grad=True) # 선형 회귀, 로지스틱 회귀에서는 b가 1이지만 이제는 클래스 개수 만큼이다.\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=0.1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He-e8kFbWMEX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "ba03ece9-b215-4a95-bb2b-f15e7d5cb15c"
      },
      "source": [
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # Cost 계산\n",
        "    z = x_train.matmul(W) + b\n",
        "    cost = F.cross_entropy(z, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch}/{nb_epochs}, Cost: {cost.item()}')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/1000, Cost: 1.0986123085021973\n",
            "Epoch 100/1000, Cost: 0.7041994333267212\n",
            "Epoch 200/1000, Cost: 0.6229996681213379\n",
            "Epoch 300/1000, Cost: 0.5657167434692383\n",
            "Epoch 400/1000, Cost: 0.5152913928031921\n",
            "Epoch 500/1000, Cost: 0.46766164898872375\n",
            "Epoch 600/1000, Cost: 0.421277791261673\n",
            "Epoch 700/1000, Cost: 0.37540167570114136\n",
            "Epoch 800/1000, Cost: 0.3297656178474426\n",
            "Epoch 900/1000, Cost: 0.28507253527641296\n",
            "Epoch 1000/1000, Cost: 0.2481546550989151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZwBr8ycWduP",
        "colab_type": "text"
      },
      "source": [
        "###4.4.3 소프트맥스 회귀 nn.Module로 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOxfA4YtWbdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델을 선언 및 초기화. 4개의 특성을 가지고 3개의 클래스로 분류. input_dim=4, output_dim=3.\n",
        "model = nn.Linear(4, 3)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5PS9sdrWpr4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "4d4d8005-bb04-4d7b-a5d5-2349d67eae38"
      },
      "source": [
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train) # F.cross_entropy() 가 소프트맥스 함수를 포함하고 있어서 가설에 정의하지 않음\n",
        "    \n",
        "    # Cost 계산\n",
        "    cost = F.cross_entropy(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch}/{nb_epochs}, Cost: {cost.item()}')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/1000, Cost: 1.8495128154754639\n",
            "Epoch 100/1000, Cost: 0.6898943781852722\n",
            "Epoch 200/1000, Cost: 0.6092584133148193\n",
            "Epoch 300/1000, Cost: 0.5512182116508484\n",
            "Epoch 400/1000, Cost: 0.5001410841941833\n",
            "Epoch 500/1000, Cost: 0.4519471228122711\n",
            "Epoch 600/1000, Cost: 0.405051052570343\n",
            "Epoch 700/1000, Cost: 0.35873302817344666\n",
            "Epoch 800/1000, Cost: 0.31291159987449646\n",
            "Epoch 900/1000, Cost: 0.26952165365219116\n",
            "Epoch 1000/1000, Cost: 0.2419215738773346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4by5SSf_XQFw",
        "colab_type": "text"
      },
      "source": [
        "###4.4.4 소프트맥스 회귀 클래스로 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA2IhGF7XITJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SoftmaxClassifierModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(4, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzI-ZfX6Xjia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SoftmaxClassifierModel()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0GhbOHEXrpi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "b4d387d1-7a3b-4f90-abfb-9752021e1108"
      },
      "source": [
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train) # F.cross_entropy() 가 소프트맥스 함수를 포함하고 있어서 가설에 정의하지 않음\n",
        "    \n",
        "    # Cost 계산\n",
        "    cost = F.cross_entropy(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch}/{nb_epochs}, Cost: {cost.item()}')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/1000, Cost: 1.845719814300537\n",
            "Epoch 100/1000, Cost: 0.6471500396728516\n",
            "Epoch 200/1000, Cost: 0.5688682198524475\n",
            "Epoch 300/1000, Cost: 0.5156992077827454\n",
            "Epoch 400/1000, Cost: 0.4717271327972412\n",
            "Epoch 500/1000, Cost: 0.43248626589775085\n",
            "Epoch 600/1000, Cost: 0.39587926864624023\n",
            "Epoch 700/1000, Cost: 0.36050641536712646\n",
            "Epoch 800/1000, Cost: 0.32522740960121155\n",
            "Epoch 900/1000, Cost: 0.2892172932624817\n",
            "Epoch 1000/1000, Cost: 0.2540856897830963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj0uFqy0AL28",
        "colab_type": "text"
      },
      "source": [
        "##4.5 소프트맥스 회귀로 MNIST 데이터 분류하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROyukvSwYIMB",
        "colab_type": "text"
      },
      "source": [
        "MNIST 데이터는 아래의 링크에 공개되어져 있다.\n",
        "\n",
        "링크 : http://yann.lecun.com/exdb/mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T8FD1koAOSd",
        "colab_type": "text"
      },
      "source": [
        "###4.5.1 MNIST 데이터 이해하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO5iMCbRYTQB",
        "colab_type": "text"
      },
      "source": [
        "![](https://camo.githubusercontent.com/06d848083b3f0d576769c6117934da8671de378b/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f36303332342f6d6e6973742e706e67)\n",
        "\n",
        "MNIST는 숫자 0부터 9까지의 이미지로 구성된 손글씨 데이터셋이다. 이 데이터는 과거에 우체국에서 편지의 우편 번호를 인식하기 위해서 만들어진 훈련 데이터이다. 총 60,000개의 훈련 데이터와 레이블, 총 10,000개의 테스트 데이터와 레이블로 구성되어져 있다. 레이블은 0부터 9까지 총 10개다. 이 예제는 머신 러닝을 처음 배울 때 접하게 되는 가장 기본적인 예제다.\n",
        "\n",
        "MNIST 문제는 손글씨로 적힌 숫자 이미지가 들어오면, 그 이미지가 무슨 숫자인지 맞추는 문제다. 예를 들어 숫자 5의 이미지가 입력으로 들어오면 이게 숫자 5다! 라는 것을 맞춰야 한다. 이 문제는 사람에게는 굉장히 간단하지만 기계에게는 그렇지가 않다.\n",
        "\n",
        "우선 MNIST 문제를 더 자세히 보자. 각각의 이미지는 아래와 같이 28 픽셀 × 28 픽셀의 이미지다.\n",
        "\n",
        "![](https://camo.githubusercontent.com/e49526e694f6e69b6b2eda80fa919c20d9acbebe/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f36303332342f6d6e6973745f535662635959472e706e67)\n",
        "\n",
        "이 문제를 풀기 위해 여기서는 28 픽셀 × 28 픽셀 = 784 픽셀이므로, 각 이미지를 총 784의 원소를 가진 벡터로 만들어줄거다. 이렇게 되면 총 784개의 특성을 가진 샘플이 되는데, 이는 앞서 우리가 풀었던 그 어떤 문제들보다 특성이 굉장히 많은 샘플이 된다.\n",
        "\n",
        "![](https://camo.githubusercontent.com/d6beaf8cdde9490a7129db3cf0ecfc2df964c665/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f36303332342f2545422538422541342545432539412542342545422541312539432545422539332539432e706e67)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6i1LlwRXvjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC2mgDiIZIy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ysf_dbCZL0o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6f52f95c-3315-4fb6-e4f4-e7c5ea9d4125"
      },
      "source": [
        "X,y = mnist_train[0]\n",
        "print('X size = ',X.size())\n",
        "print('입력 이미지를 [batch_size × 784]의 크기로 reshape 하면 X size = ',X.view(-1, 28*28).size())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X size =  torch.Size([1, 28, 28])\n",
            "입력 이미지를 [batch_size × 784]의 크기로 reshape 하면 X size =  torch.Size([1, 784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2An_5GkPAX-l",
        "colab_type": "text"
      },
      "source": [
        "### 4.5.2 토치비전(torchvision) 소개하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUZ2P8KOZQWp",
        "colab_type": "text"
      },
      "source": [
        "본격적인 실습에 들어가기에 앞서 토치비전(torchvision)이라는 도구를 설명하겠다. \n",
        "\n",
        "torchvision은 유명한 데이터셋들, 이미 구현되어져 있는 유명한 모델들, 일반적인 이미지 전처리 도구들을 포함하고 있는 패키지다. \n",
        "\n",
        "아래의 링크는 torchvision에 어떤 데이터셋들(datasets)과 모델들(models) 그리고 어떤 전처리 방법들(transforms)을 제공하고 있는지 보여준다.\n",
        "\n",
        "링크 : https://pytorch.org/docs/stable/torchvision/index.html\n",
        "\n",
        "자연어 처리를 위해서는 토치텍스트(torchtext)라는 패키지가 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv5Afu_fZfrA",
        "colab_type": "text"
      },
      "source": [
        "### 4.5.3 분류기 구현을 위한 사전 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp23N7TgZO84",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "908e94a0-460b-4bbf-cfcd-65014e7725fa"
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available() # GPU를 사용가능하면 True, 아니라면 False를 리턴\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\") # GPU 사용 가능하면 사용하고 아니면 CPU 사용\n",
        "print(\"다음 기기로 학습합니다:\", device)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "다음 기기로 학습합니다: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O47xEv2oZ09j",
        "colab_type": "text"
      },
      "source": [
        "구글의 Colab에서 '런타임 > 런타임 유형 변경 > 하드웨어 가속기 > GPU'를 선택하면 USE_CUDA의 값이 True가 되면서 '다음 기기로 학습합니다: cuda'라는 출력이 나온다.\n",
        "\n",
        "즉, GPU로 연산하겠다는 의미다. 반면에 '하드웨어 가속기 > None'을 선택하면 USE_CUDA의 값이 False가 되면서 '다음 기기로 학습합니다: cpu'라는 출력이 나온다. 즉, CPU로 연산하겠다는 의미다.\n",
        "\n",
        "위의 방법은 앞으로 자주 쓰이게되므로 기억하자.\n",
        "\n",
        "랜덤 시드를 고정하자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31sjJPbjZroM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for reproducibility\n",
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10LnFeEYaFw1",
        "colab_type": "text"
      },
      "source": [
        "### 4.5.4 MNIST 분류기 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRn5WiNqaCiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST dataset\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KknR51Ieb99v",
        "colab_type": "text"
      },
      "source": [
        "첫번째 인자 root : MNIST 데이터를 다운로드 받을 경로\n",
        "\n",
        "두번째 인자 train : True를 주면 MNIST의 훈련 데이터를 리턴, False를 주면 테스트 데이터를 리턴\n",
        "\n",
        "세번째 인자 transform : 현재 데이터를 파이토치 텐서로 변환\n",
        "\n",
        "네번째 인자 download : 해당 경로에 MNIST 데이터가 없다면 다운로드 받겠다는 의미\n",
        "\n",
        "이렇게 데이터를 다운로드했다면 앞서 미니 배치와 데이터로드 챕터에서 학습했던 데이터로더(DataLoader)를 사용하자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXX_kadJqmnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hyperparameters를 변수로 두고 시작한다.\n",
        "training_epochs = 15 # nb_epochs의 기능과 같다.\n",
        "batch_size = 100"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mxa4NQhb6Yc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset loader\n",
        "data_loader = DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size, # 배치 크기는 100\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True) # drop_last는 데이터를 배치 크기에 맞게 나눈 후(여기서는 100씩) 나머지(여기서는 100보다 작은 수)를 버린다는 의미다."
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmqt7vM4ccIz",
        "colab_type": "text"
      },
      "source": [
        "이때 DataLoader에는 4개의 인자가 있다.\n",
        "\n",
        "첫번째 인자 DataLoader : 로드할 대상을 의미\n",
        "\n",
        "두번째 인자 batch_size : 배치 크기\n",
        "\n",
        "세번째 인자 shuffle : 매 에포크마다 미니 배치를 셔플할 것인지의 여부\n",
        "\n",
        "네번째 인자 drop_last : 마지막 배치를 버릴 것인지를 의미합니다.\n",
        "\n",
        "drop_last를 하는 이유 : 예를 들어, 1,000개의 데이터가 있다고 했을 때 배치 크기가 128이라고 해보자. 1,000을 128로 나누면 총 7개가 나오고 나머지로 104개가 남는다. 이때 104개를 마지막 배치로 한다고 하였을 때 128개를 충족하지 못하였으므로 104개를 그냥 버릴 수도 있다. 이때 마지막 배치를 버리려면 drop_last=True를 해주면 된다. 이는 다른 미니 배치보다 개수가 적은 마지막 배치를 경사 하강법에 사용하여 마지막 배치가 상대적으로 과대 평가되는 현상을 막아준다.\n",
        "\n",
        "이제 모델을 설계하자. input_dim은 784이고, output_dim은 10이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUVTn9pKdX18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST data image of shape 28 * 28 = 784\n",
        "model = nn.Linear(784, 10, bias=True).to(device)\n",
        "# 비용 함수와 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss().to(device) # 내부적으로 소프트맥스 함수를 포함하고 있음.\n",
        "# 크라이티어리언, 표준이라는 뜻, 굳이 안써도 되는데 왜쓰는지 모르겠다.\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwghsMwBdgCo",
        "colab_type": "text"
      },
      "source": [
        "to() 함수는 연산을 어디서 수행할지를 정한다. \n",
        "\n",
        "to() 함수는 모델의 매개변수를 지정한 장치의 메모리로 보낸다. \n",
        "\n",
        "CPU를 사용할 경우에는 필요가 없지만, GPU를 사용하려면 to('cuda')를 해 줄 필요가 있다. \n",
        "\n",
        "아무것도 지정하지 않은 경우에는 CPU 연산이라고 보면 된다.\n",
        "\n",
        "bias는 편향 b를 사용할 것인지를 나타낸다. 기본값은 True이므로 굳이 할 필요는 없지만 명시적으로 True를 해주었다.\n",
        "\n",
        "앞서 소프트맥스 회귀를 배울 때는 torch.nn.functional.cross_entropy()를 사용하였으나 여기서는 torch.nn.CrossEntropyLoss()을 사용하고 있다. \n",
        "\n",
        "둘 다 파이토치에서 제공하는 크로스 엔트로피 함수로 소프트맥스 함수를 포함하고 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhUWXpljdv8i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "026c52af-7cd3-44c4-8ebe-d3341fc6932b"
      },
      "source": [
        "for epoch in range(training_epochs): # 앞서 training_epochs의 값은 15로 지정함.\n",
        "  avg_cost = 0 \n",
        "  \"\"\"\n",
        "  나는 한 epoch 당 cost를 알고 싶다.(60,000개로 한 바퀴 돌렸을 때의 cost) \n",
        "  근데 여기서 cost는 batch 마다 나온다. (한 배치인 100개를 돌렸을 때의 cost) \n",
        "  그래서 각 배치에서의 cost를 모두 더 한후 batch의 수 만큼 나눠줄거다.\n",
        "  \"\"\"\n",
        "  num_batch = len(data_loader) # 60,000개를 100개씩 나누었으니 600개의 batch가 생긴다.\n",
        "    \n",
        "  for X, Y in data_loader:\n",
        "    # 배치 크기가 100이므로 아래의 연산에서 X는 (100, 784)의 텐서가 된다.\n",
        "    X = X.view(-1, 28 * 28).to(device)\n",
        "    # 레이블은 원-핫 인코딩이 된 상태가 아니라 0 ~ 9의 정수.\n",
        "    Y = Y.to(device)\n",
        "    \n",
        "    # H(x) 계산\n",
        "    hypothesis = model(X)\n",
        "\n",
        "    # Cost 계산\n",
        "    cost = criterion(hypothesis, Y)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print(f'cost : {cost}')\n",
        "    avg_cost += cost / num_batch\n",
        "\n",
        "  print(f'Epoch : {epoch}, Cost : {avg_cost}')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0, Cost : 0.5354685187339783\n",
            "Epoch : 1, Cost : 0.35927414894104004\n",
            "Epoch : 2, Cost : 0.33118751645088196\n",
            "Epoch : 3, Cost : 0.31657806038856506\n",
            "Epoch : 4, Cost : 0.30715814232826233\n",
            "Epoch : 5, Cost : 0.30018073320388794\n",
            "Epoch : 6, Cost : 0.2951302230358124\n",
            "Epoch : 7, Cost : 0.29085150361061096\n",
            "Epoch : 8, Cost : 0.28741705417633057\n",
            "Epoch : 9, Cost : 0.2843795418739319\n",
            "Epoch : 10, Cost : 0.2818252146244049\n",
            "Epoch : 11, Cost : 0.2798007130622864\n",
            "Epoch : 12, Cost : 0.2778090238571167\n",
            "Epoch : 13, Cost : 0.2761543095111847\n",
            "Epoch : 14, Cost : 0.27444085478782654\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNbXhUEyecM9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "8214357a-6580-4fd5-9aea-5a815046bed8"
      },
      "source": [
        "# 테스트 데이터를 사용하여 모델을 테스트한다.\n",
        "with torch.no_grad(): # torch.no_grad()를 하면 gradient 계산을 수행하지 않는다.\n",
        "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "    prediction = model(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())\n",
        "\n",
        "    # MNIST 테스트 데이터에서 무작위로 하나를 뽑아서 예측을 해본다\n",
        "    r = random.randint(0, len(mnist_test) - 1)\n",
        "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
        "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
        "\n",
        "    print('Label: ', Y_single_data.item())\n",
        "    single_prediction = model(X_single_data)\n",
        "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
        "\n",
        "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
        "    plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8862999677658081\n",
            "Label:  5\n",
            "Prediction:  3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:60: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:50: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux48RIQbem2W",
        "colab_type": "text"
      },
      "source": [
        "torch.no_grad() 와 model.eval()\n",
        "\n",
        "공통점 : 범위 안에서는 gradient 계산을 하지 않는다.\n",
        "\n",
        "차이점 : torch.no_grad()는 해당 범위 안에서 gradient 계산을 중지시킴으로써 메모리 사용량을 줄이고 계산 속도를 빨리 한다.\n",
        "\n",
        "model.train()과 model.eval()은 모델이 학습 모드인지, 테스트 모드인지를 정하는 것이다. dropout이나 batchnorm이 있는 모델의 경우 학습할 때와 테스트할 때 모델이 달라지기 때문에 세팅한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u_kuckT0Lyo",
        "colab_type": "text"
      },
      "source": [
        "##4.6 활용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExrrunF70Pxf",
        "colab_type": "text"
      },
      "source": [
        "출처 : https://github.com/Namsik-Yoon/pytorch_basic/blob/master/4_1_%EC%86%8C%ED%94%84%ED%8A%B8%EB%A7%A5%EC%8A%A4_%ED%9A%8C%EA%B7%80_with_My_data.ipynb\n",
        "\n",
        "sklearn에서 제공하는 미국 삼림 수종 데이터를 바탕으로 소프트맥스 회귀모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhji6hyH0OZa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "4adf71af-f3d6-4d86-a602-41e6922e4ea7"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_covtype\n",
        "\n",
        "covtype = fetch_covtype()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/datasets/_covtype.py\u001b[0m in \u001b[0;36mfetch_covtype\u001b[0;34m(data_home, download_if_missing, random_state, shuffle, return_X_y)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'X' referenced before assignment",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-9dab1b776fa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_covtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcovtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_covtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/datasets/_covtype.py\u001b[0m in \u001b[0;36mfetch_covtype\u001b[0;34m(data_home, download_if_missing, random_state, shuffle, return_X_y)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_refresh_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msamples_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO: Revert to the following two lines in v0.23\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;31m# X = joblib.load(samples_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/datasets/_base.py\u001b[0m in \u001b[0;36m_refresh_cache\u001b[0;34m(files, compress)\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sklearn.externals.joblib is deprecated in 0.21\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwarns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0mrefresh_needed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwarns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/datasets/_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sklearn.externals.joblib is deprecated in 0.21\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwarns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0mrefresh_needed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwarns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    583\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
            "\u001b[0;32m/usr/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1048\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload_build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNDArrayWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;31m# Be careful to register our new method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, unpickler)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpickler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpickler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# Manage array subclass case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(self, unpickler)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mread_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_count\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 data = _read_bytes(unpickler.file_handle,\n\u001b[0;32m--> 138\u001b[0;31m                                    read_size, \"array data\")\n\u001b[0m\u001b[1;32m    139\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mread_count\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                     unpickler.np.frombuffer(data, dtype=self.dtype,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/numpy_pickle_utils.py\u001b[0m in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"EOF: reading %s, expected %d bytes got %d\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merror_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: EOF: reading array data, expected 262144 bytes got 176446"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbhLX8KU0ZeP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "53701ff0-2ef6-4a94-e288-4f5a6f6c8806"
      },
      "source": [
        "print(covtype.DESCR)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-b838572d566d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDESCR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'covtype' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrZEWflD0bIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "covtype_df = pd.DataFrame(data=covtype['data'])\n",
        "covtype_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AdiOaQZ0dhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = covtype_df\n",
        "data = data.apply(\n",
        "    lambda x: (x - x.mean()) / x.std()\n",
        ")\n",
        "data['target'] = covtype['target']-1\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxZPDbuL0fWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X,y = data.values[:,:-1],data.values[:,-1:]\n",
        "print(X.shape,y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuWeAC5t0gn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTtgNwiI0jL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.x_data = torch.FloatTensor(X)\n",
        "        self.y_data = torch.LongTensor(y)\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        x = self.x_data[idx]\n",
        "        y = self.y_data[idx]\n",
        "        return x,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFDkXNO00mHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = MyDataset()\n",
        "dataloader = DataLoader(dataset, batch_size=len(dataset), shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCzWBCK80oLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SoftmaxClassifierModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(54, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8mxKzyu0pck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SoftmaxClassifierModel()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlftA0eX0tbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_epochs = 100\n",
        "for epoch in range(nb_epochs + 1):\n",
        "    for x_train,y_train in dataloader:\n",
        "        y_train = y_train.squeeze(1)\n",
        "        # H(x) 계산\n",
        "        hypothesis = model(x_train)\n",
        "        # cost 계산\n",
        "        cost=criterion(hypothesis, y_train)\n",
        "        # cost로 H(x) 개선\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        correct_prediction = torch.argmax(hypothesis,dim=1) == y_train # 실제값과 일치하는 경우만 True로 간주\n",
        "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
        "        print(f'Epoch : {epoch}/{nb_epochs}, Cost: {cost.item()}, Accuracy : {accuracy * 100}%')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29sYQ789hlfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}